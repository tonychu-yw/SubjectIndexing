{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"sampling.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit ('base': conda)"},"language_info":{"name":"python","version":"3.8.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"0d8bf6801b9e0c14e5026b6134fd4f1a5633696379168a96ecf2f6cc9392dd51"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["cd .. "],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import numpy as np\r\n","import pandas as pd"],"outputs":[],"metadata":{"id":"y9iOmyE1by0x"}},{"cell_type":"markdown","source":["# Create datasets"],"metadata":{"id":"Rp7S0_eGd-U4"}},{"cell_type":"code","execution_count":null,"source":["# import fulldata\r\n","dataset = pd.read_json('./data/interim/dataset.json')\r\n","\r\n","# import subclasses metadata\r\n","with open(\"./work/subclasses.txt\", encoding='utf-8') as f:\r\n","    lines = f.readlines()\r\n","lc_subclasses = {}\r\n","for i in range(len(lines)):\r\n","    lc_subclasses[lines[i][0]] = lines[i][2:].replace(\" \", \"\").replace(\"\\n\", \"\").split(\",\")"],"outputs":[],"metadata":{"id":"7qH463jhG9oi"}},{"cell_type":"code","execution_count":null,"source":["# extract subclass and class from books metadata\r\n","window = 4096\r\n","skip = 500\r\n","idx, X, y_class, y_subclass = [], [], [], []\r\n","for cls in lc_subclasses:\r\n","    for i in range(len(dataset)):\r\n","        for sub in dataset.subjects_new[i]:\r\n","            if sub in lc_subclasses[cls]:\r\n","                idx.append(dataset.id[i])\r\n","                tokens = ' '.join(dataset.text[i].split()[skip:4096+skip])\r\n","                X.append(tokens)\r\n","                y_class.append(cls) \r\n","                y_subclass.append(sub)\r\n","fullset = pd.DataFrame({'id':idx, 'X':X, 'y_class':y_class, 'y_subclass':y_subclass})"],"outputs":[],"metadata":{"id":"pJefUrRjiWBD"}},{"cell_type":"code","execution_count":null,"source":["fullset.head()"],"outputs":[],"metadata":{"id":"tFS9lFvuT00N"}},{"cell_type":"code","execution_count":null,"source":["fullset.groupby('y_class').count().id  # note that the classes are highly unbalanced"],"outputs":[],"metadata":{"id":"SbWuaxYajTCJ"}},{"cell_type":"markdown","source":["# Train test split"],"metadata":{"id":"wBtOzdiQqkur"}},{"cell_type":"code","execution_count":null,"source":["# train test split \r\n","np.random.seed(0)\r\n","msk1 = np.random.rand(len(fullset)) < 0.8\r\n","test_set = fullset.copy()[~msk1]\r\n","train_set = fullset.copy()[msk1]\r\n","np.random.seed(1)\r\n","msk2 = np.random.rand(len(train_set)) < 0.8\r\n","val_set = train_set.copy()[~msk2]\r\n","train_set = train_set.copy()[msk2]"],"outputs":[],"metadata":{"id":"J8xL2mc24ggs"}},{"cell_type":"markdown","source":["# Sampling"],"metadata":{"id":"CwEeV6DyqoEj"}},{"cell_type":"code","execution_count":null,"source":["# undersample majority and oversample minority classes\r\n","train_sample = []\r\n","for cls in list(set(fullset.y_class)):\r\n","    length = train_set[train_set['y_class'] == cls].shape[0]\r\n","    if length % 2 != 0:\r\n","        length -= 1\r\n","    if length >= 1000:\r\n","        sample = train_set[train_set['y_class'] == cls].sample(n=1000, replace=False, random_state=0)\r\n","    elif length < 1000:\r\n","        sample = train_set[train_set['y_class'] == cls].sample(n=max(length, 500), replace=(length<500), random_state=0)   \r\n","    train_sample.append(sample)"],"outputs":[],"metadata":{"id":"UV_v-Q86kKl0"}},{"cell_type":"code","execution_count":null,"source":["def sampling(data_set, max_sample_size):\r\n","    \"\"\"\r\n","    Sample from dataset by class. Undersample if class n > max_sample_size.\r\n","    \"\"\"\r\n","  \r\n","    sample_list = []\r\n","    for cls in list(set(fullset.y_class)):\r\n","        length = data_set[data_set['y_class'] == cls].shape[0]\r\n","        if length % 2 != 0:  # make sure that batch size is can be even\r\n","            length -= 1\r\n","        sample = data_set[data_set['y_class'] == cls].sample(n=min(length, max_sample_size), replace=False, random_state=0)\r\n","        sample_list.append(sample)\r\n","\r\n","    return sample_list"],"outputs":[],"metadata":{"id":"Zn1r8p9mopXA"}},{"cell_type":"code","execution_count":null,"source":["# undersample majority class\r\n","val_sample = sampling(val_set, 100)\r\n","test_sample = sampling(test_set, 100)"],"outputs":[],"metadata":{"id":"n9STThSfNegR"}},{"cell_type":"code","execution_count":null,"source":["# transform to pandas df\r\n","train_set = pd.concat(train_sample)\r\n","val_set = pd.concat(val_sample)\r\n","test_set = pd.concat(test_sample)\r\n","fullset.shape, train_set.shape, val_set.shape, test_set.shape"],"outputs":[],"metadata":{"id":"hpLqZGAYnF-d"}},{"cell_type":"markdown","source":["# Save dataframes"],"metadata":{"id":"WYEP9MP5qtxj"}},{"cell_type":"code","execution_count":null,"source":["fullset.reset_index(drop=True).to_json('./data/final/full_set.json')\r\n","train_set.reset_index(drop=True, inplace=True)\r\n","train_set.reset_index(drop=True).to_json('./data/final/train_set.json')\r\n","val_set.reset_index(drop=True).to_json('./data/final/val_set.json')\r\n","test_set.reset_index(drop=True).to_json('./data/final/test_set.json')"],"outputs":[],"metadata":{"id":"_SI7fQHfXGEH"}}]}