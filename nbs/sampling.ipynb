{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sampling.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3.7.11 64-bit"},"language_info":{"name":"python","version":"3.7.11"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ADvTvesxuWfi"},"source":["# Setup"]},{"cell_type":"code","metadata":{"id":"9jsUSpthuTHm"},"source":["# mount drive \n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNzhsNC6uZI3"},"source":["cd \"/content/gdrive/My Drive/Github/lc-classification\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y9iOmyE1by0x"},"source":["import numpy as np\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rp7S0_eGd-U4"},"source":["# Create datasets"]},{"cell_type":"code","metadata":{"id":"7qH463jhG9oi"},"source":["# import fulldata\n","dataset = pd.read_json('./data/interim/dataset.json')\n","\n","# import subclasses metadata\n","with open(\"./work/subclasses.txt\", encoding='utf-8') as f:\n","    lines = f.readlines()\n","lc_subclasses = {}\n","for i in range(len(lines)):\n","    lc_subclasses[lines[i][0]] = lines[i][2:].replace(\" \", \"\").replace(\"\\n\", \"\").split(\",\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pJefUrRjiWBD"},"source":["# extract subclass and class from books metadata\n","window = 4096\n","skip = 500\n","idx, X, y_class, y_subclass = [], [], [], []\n","for cls in lc_subclasses:\n","    for i in range(len(dataset)):\n","        for sub in dataset.subjects_new[i]:\n","            if sub in lc_subclasses[cls]:\n","                idx.append(dataset.id[i])\n","                tokens = ' '.join(dataset.text[i].split()[skip:4096+skip])\n","                X.append(tokens)\n","                y_class.append(cls) \n","                y_subclass.append(sub)\n","fullset = pd.DataFrame({'id':idx, 'X':X, 'y_class':y_class, 'y_subclass':y_subclass})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tFS9lFvuT00N"},"source":["fullset.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SbWuaxYajTCJ"},"source":["fullset.groupby('y_class').count().id  # note that the classes are highly unbalanced"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wBtOzdiQqkur"},"source":["# Train test split"]},{"cell_type":"code","metadata":{"id":"J8xL2mc24ggs"},"source":["# train test split \n","np.random.seed(0)\n","msk1 = np.random.rand(len(fullset)) < 0.8\n","test_set = fullset.copy()[~msk1]\n","train_set = fullset.copy()[msk1]\n","np.random.seed(1)\n","msk2 = np.random.rand(len(train_set)) < 0.8\n","val_set = train_set.copy()[~msk2]\n","train_set = train_set.copy()[msk2]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CwEeV6DyqoEj"},"source":["# Sampling"]},{"cell_type":"code","metadata":{"id":"UV_v-Q86kKl0"},"source":["# undersample majority and oversample minority classes\n","train_sample = []\n","for cls in list(set(fullset.y_class)):\n","    length = train_set[train_set['y_class'] == cls].shape[0]\n","    if length % 2 != 0:\n","        length -= 1\n","    if length >= 1000:\n","        sample = train_set[train_set['y_class'] == cls].sample(n=1000, replace=False, random_state=0)\n","    elif length < 1000:\n","        sample = train_set[train_set['y_class'] == cls].sample(n=max(length, 500), replace=(length<500), random_state=0)   \n","    train_sample.append(sample)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zn1r8p9mopXA"},"source":["def sampling(data_set, max_sample_size):\n","    \"\"\"\n","    Sample from dataset by class. Undersample if class n > max_sample_size.\n","    \"\"\"\n","  \n","    sample_list = []\n","    for cls in list(set(fullset.y_class)):\n","        length = data_set[data_set['y_class'] == cls].shape[0]\n","        if length % 2 != 0:  # make sure that batch size is can be even\n","            length -= 1\n","        sample = data_set[data_set['y_class'] == cls].sample(n=min(length, max_sample_size), replace=False, random_state=0)\n","        sample_list.append(sample)\n","\n","    return sample_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n9STThSfNegR"},"source":["# undersample majority class\n","val_sample = sampling(val_set, 100)\n","test_sample = sampling(test_set, 100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hpLqZGAYnF-d"},"source":["# transform to pandas df\n","train_set = pd.concat(train_sample)\n","val_set = pd.concat(val_sample)\n","test_set = pd.concat(test_sample)\n","fullset.shape, train_set.shape, val_set.shape, test_set.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WYEP9MP5qtxj"},"source":["# Save dataframes"]},{"cell_type":"code","metadata":{"id":"_SI7fQHfXGEH"},"source":["fullset.to_json('./data/final/full_set.json')\n","train_set.reset_index(drop=True, inplace=True)\n","train_set.to_json('./data/final/train_set.json')\n","val_set.to_json('./data/final/val_set.json')\n","test_set.to_json('./data/final/test_set.json')"],"execution_count":null,"outputs":[]}]}