{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataset.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3.7.11 64-bit"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"cells":[{"cell_type":"code","metadata":{"id":"O1Ul0WdFYInV"},"source":["import sys\n","sys.path.append('../src')\n","from utils.data import *"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b01wgPGzlcch"},"source":["# Clean data"]},{"cell_type":"code","metadata":{"id":"LSK0OeY3YSZ7"},"source":["# combine book txt files to a json (warning: may have MemoryError)\n","clean_books(\n","    \"data/raw/text\",                          # folder directory where the TXT books are stored\n","    \"data/interim/text.json\",                 # output file directory (.json)\n","    n_tokens = 8000                           # extract first n tokens with .split() tokenization\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Si_6oGDuZZhR"},"source":["# extract required metadata (e.g., title, subjects) from the raw data\n","extract_metadata(\n","    \"data/raw/metadata\",                      # folder directory where the metadata RDF files are stored\n","    \"data/interim/metadata.json\"              # output file directory (.json)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NcDcYCcHZ787"},"source":["# remove metadata not in the downloaded books and remove suffix in subjects (words after --) \n","clean_metadata(\n","    \"data/interim/metadata.json\",             # input file directory for metadata (.json)\n","    \"data/raw/text\",                          # folder directory where the text files are stored\n","    \"data/interim/metadata.json\"              # output file directory (.json)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sOLNF4YYlccj"},"source":["# Combine text and metadata"]},{"cell_type":"code","metadata":{"id":"blP_-Yx4mAm7"},"source":["# import book texts and metadata\n","text = pd.read_json(\"data/interim/text.json\", typ=\"series\")\n","text = pd.DataFrame({\"id\": text.index, \"text\": text})\n","metadata = pd.read_json(\"data/interim/metadata.json\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xl_BpBZ0rHex"},"source":["# merge text and metadata\n","dataset = pd.merge(metadata, text, how=\"left\", left_on='id', right_on='id', sort=True)\n","dataset.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c5pDFBkslcck"},"source":["# save dataset as json\n","dataset.to_json(\"data/interim/dataset.json\")"],"execution_count":null,"outputs":[]}]}