{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Main.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyMTKZh4qUIj3lW9BV4RRiCp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ADvTvesxuWfi"},"source":["# Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9jsUSpthuTHm","executionInfo":{"status":"ok","timestamp":1622440530383,"user_tz":420,"elapsed":564,"user":{"displayName":"Tony Chu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg34pG5yft_9twqehpodxKWt7CLMVt1kRnlSI2U=s64","userId":"04992041947822798791"}},"outputId":"4179b70f-038a-402e-f492-2b12bb45dd8c"},"source":["# mount drive \n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VNzhsNC6uZI3","executionInfo":{"status":"ok","timestamp":1622440530385,"user_tz":420,"elapsed":12,"user":{"displayName":"Tony Chu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg34pG5yft_9twqehpodxKWt7CLMVt1kRnlSI2U=s64","userId":"04992041947822798791"}},"outputId":"ec8a2786-35f6-4c50-ec99-2527d5a39784"},"source":["cd \"/content/gdrive/My Drive/Github/SubjectIndexing\""],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Github/SubjectIndexing\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6lZCxIHxuruI","executionInfo":{"status":"ok","timestamp":1622440536068,"user_tz":420,"elapsed":5690,"user":{"displayName":"Tony Chu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg34pG5yft_9twqehpodxKWt7CLMVt1kRnlSI2U=s64","userId":"04992041947822798791"}}},"source":["# general\n","import time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# PCA for plotting \n","from sklearn.decomposition import PCA\n","\n","# custom library for transformers\n","from lib.embeddings import Book2Vec"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MKk6cwaYut4O"},"source":["# Create Embeddings"]},{"cell_type":"code","metadata":{"id":"YIO4tcHguuaM","executionInfo":{"status":"ok","timestamp":1622440536545,"user_tz":420,"elapsed":482,"user":{"displayName":"Tony Chu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg34pG5yft_9twqehpodxKWt7CLMVt1kRnlSI2U=s64","userId":"04992041947822798791"}}},"source":["# import dataset\n","df = pd.read_json('./data/dataset_B.json')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6nZonK4OXygB","outputId":"aec498e8-e6b4-400a-b07e-cfcbf738ce87"},"source":["# calculate embeddings module \n","book2vec = Book2Vec(tokenizer='allenai/longformer-base-4096', model='allenai/longformer-base-4096')\n","X_embeddings = book2vec.get_embeddings(df.X)\n","Book2Vec.save_embeddings(X_embeddings, './models/embeddings_classB_last4layers.pkl')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["1000 - time: 4 min 39 sec\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"beOXbsWt4SEe"},"source":["# Plot "]},{"cell_type":"code","metadata":{"id":"yBNev4jP0MtV"},"source":["# conduct PCA for graphical representation\n","pca = PCA(n_components=2)\n","embeddings_2d = pca.fit_transform(X_embeddings)\n","print(pca.explained_variance_ratio_.sum())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ddMlhRK0ekx"},"source":["df['2d_x'] = embeddings_2d[:,0]\n","df['2d_y'] = embeddings_2d[:,1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V0muoyGx0Vy4"},"source":["plt.figure(figsize=(12,8))\n","plt.scatter(df[df['y'] == 'B']['2d_x'], df[df['y'] == 'B']['2d_y'], c='lightgrey', s=48, label='B - Philosophy')\n","plt.scatter(df[df['y'] == 'BC']['2d_x'], df[df['y'] == 'BC']['2d_y'], c='tab:blue', s=48, label='BC - Logic')\n","plt.scatter(df[df['y'] == 'BH']['2d_x'], df[df['y'] == 'BH']['2d_y'], c='tab:orange', s=48, marker='s',label='BH - Aesthetics')\n","plt.scatter(df[df['y'] == 'BJ']['2d_x'], df[df['y'] == 'BJ']['2d_y'], c='tab:green', s=48, marker='^', label='BJ - Ethics')\n","#plt.scatter(df[df['y'] == 'BS']['2d_x'], df[df['y'] == 'BS']['2d_y'], c='tab:cyan', s=52, marker='^', label='BS - The Bible')\n","plt.title(\"Books in Section B (Embedding Space)\")\n","plt.xlabel(\"PCA1\")\n","plt.ylabel(\"PCA2\")\n","#for i, txt in enumerate([str(x) for x in list(books_B.keys())]):\n","#    plt.annotate(txt, (embeddings_2d[:,0][i], embeddings_2d[:,1][i]))\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C3OB8y3Kibbo"},"source":["plt.figure(figsize=(12,8))\n","plt.scatter(df[df['y'] == 'B']['2d_x'], df[df['y'] == 'B']['2d_y'], c='lightgrey', s=48, label='B - Philosophy')\n","plt.scatter(df[df['y'] == 'BR']['2d_x'], df[df['y'] == 'BR']['2d_y'], c='tab:blue', s=48, label='BR - Christianity')\n","#plt.scatter(df[df['y'] == 'BS']['2d_x'], df[df['y'] == 'BS']['2d_y'], c='tab:blue', s=48, label='BS - The Bible')\n","#plt.scatter(df[df['y'] == 'BT']['2d_x'], df[df['y'] == 'BT']['2d_y'], c='tab:orange', s=48, marker='d', label='BT - Doctrinal Theology')\n","plt.scatter(df[df['y'] == 'BM']['2d_x'], df[df['y'] == 'BM']['2d_y'], c='tab:orange', s=48, marker='s', label='BM - Judaism')\n","plt.scatter(df[df['y'] == 'BP']['2d_x'], df[df['y'] == 'BP']['2d_y'], c='tab:green', s=48, marker='^', label='BP - Islam. Bahaism. Theosophy, etc.')\n","plt.title(\"Books in Section B (Embedding Space)\")\n","plt.xlabel(\"PCA1\")\n","plt.ylabel(\"PCA2\")\n","#for i, txt in enumerate([str(x) for x in list(books_B.keys())]):\n","#    plt.annotate(txt, (embeddings_2d[:,0][i], embeddings_2d[:,1][i]))\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8PzxEKos4N4x"},"source":["# Classification"]},{"cell_type":"code","metadata":{"id":"xi7a-G3b3Jvs"},"source":["# sklearn models\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","\n","# sklearn utilities\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.metrics import accuracy_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nfIx_XW54ZLz"},"source":["X_train, X_test, y_train, y_test = train_test_split(X_embeddings, df.y, test_size=0.2, shuffle=True, random_state=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"09AN2Xfi24YK"},"source":["## Random Forest"]},{"cell_type":"code","metadata":{"id":"IWEl0n9FgtLn"},"source":["start = time.time()\n","rf = RandomForestClassifier(n_estimators=500, max_depth=5, random_state=0)\n","rf_scores = cross_val_score(rf, X_train, y_train, cv=5)\n","print(np.mean(rf_scores))\n","end = time.time()\n","print(\"Total runtime:\", round((end-start)//60), \"min\",  round((end-start)%60), \"sec\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iuqtt7uj21_5"},"source":["## Gradient Boosting"]},{"cell_type":"code","metadata":{"id":"HYxgC11Kv7AR"},"source":["start = time.time()\n","gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.01, max_depth=5, random_state=0)\n","gb_scores = cross_val_score(gb, X_train, y_train, cv=5)\n","print(np.mean(gb_scores))\n","end = time.time()\n","print(\"Total runtime:\", round((end-start)//60), \"min\",  round((end-start)%60), \"sec\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ev4app5R20xf"},"source":["## SVM"]},{"cell_type":"code","metadata":{"id":"A9gojX4wwFSv"},"source":["start = time.time()\n","svm = make_pipeline(StandardScaler(), SVC(C=10, gamma='scale', random_state=0))\n","svm_scores = cross_val_score(svm, X_train, y_train, cv=5)\n","print(np.mean(svm_scores))\n","end = time.time()\n","print(\"Total runtime:\", round((end-start)//60), \"min\",  round((end-start)%60), \"sec\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1MIH2UOP27sN"},"source":["## Neural Net"]},{"cell_type":"code","metadata":{"id":"r38FvzU628_5"},"source":["import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5LQDLhYF48dF"},"source":["labels = sorted(list(set(y_train)))\n","class2label = {}\n","for i in range(len(labels)):\n","    class2label[labels[i]] = i\n","y_train_labels = [class2label[l] for l in y_train]\n","y_train_oh = to_categorical(y_train_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wgGfVukN3QlT"},"source":["# model structure\n","input = tf.keras.Input(shape=(X_train.shape[1],))\n","x = tf.keras.layers.Dense(1024, activation='relu')(input)\n","x = tf.keras.layers.Dense(256, activation='relu')(x)\n","x = tf.keras.layers.Dense(64, activation='relu')(x)\n","output = tf.keras.layers.Dense(len(set(labels)), activation='softmax')(x)\n","model = tf.keras.Model(inputs=input, outputs=output)\n","\n","# compile model\n","model.compile(\n","    loss = 'sparse_categorical_crossentropy', \n","    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4),\n","    metrics = ['sparse_categorical_accuracy']]\n",")\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_eSf6xgH36JD"},"source":["# train model\n","history = model.fit(\n","    X_train, y_train_labels, validation_split=0.2, shuffle=True,\n","    batch_size=256, epochs=50, verbose=1,\n","    callbacks=[EarlyStopping(monitor='val_loss', patience=5, min_delta=0.001, restore_best_weights=True)]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wqgeDHVY4Api"},"source":["# print training history\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(loss))\n","plt.plot(epochs, acc, 'tab:red', label='Training Acc')\n","plt.plot(epochs, val_acc, 'tab:blue', label='Validation Acc')\n","plt.title('Training and validation Acc')\n","plt.legend()\n","plt.plot(epochs, loss, 'tab:red', label='Training Loss')\n","plt.plot(epochs, val_loss, 'tab:blue', label='Validation Loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","plt.figure()\n","plt.show()"],"execution_count":null,"outputs":[]}]}